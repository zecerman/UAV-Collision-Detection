import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor





df = pd.read_csv('binned_mid360_lidar_25_first.csv')
print(df.head(5))

df_action = pd.read_csv("mid360_livox_imu.csv")
df_action.drop("Unnamed: 0", axis = 1, inplace = True)
df_action = df_action.loc[:, (df_action != 0).any(axis=0)]
print(df_action.head(5))

df_pose = pd.read_csv('vrpn_client_node-holybro-pose.csv')





def parse_points(raw_string, frame_id=None):
    raw_string = raw_string.strip("[]")
    entries = raw_string.split(", ")
    parsed = []
    for entry in entries:
        fields = entry.split(";")
        point = {}
        for field in fields:
            if ":" in field:
                key, value = field.split(":", 1)
                point[key.strip()] = value.strip()
        if frame_id is not None:
            point['frame_id'] = frame_id  # Track source frame
        parsed.append(point)
    return parsed

# Apply to all rows
all_points = []
for idx, row in df.iterrows():
    raw = row['points']
    frame_id = row.get('frame_index', idx)  # Use frame_index if available
    try:
        parsed = parse_points(raw, frame_id)
        for point in parsed:
            for col in df.columns:
                if col != 'points':
                    point[col] = row[col]
        all_points.extend(parsed)
    except Exception as e:
        print(f"Error parsing row {idx}: {e}")

# Convert to DataFrame
points_df = pd.DataFrame(all_points)
points_df = points_df.apply(pd.to_numeric, errors='ignore')

points_df.drop(["header.frame_id", "Unnamed: 0", "rsvd"], axis = 1, inplace = True)


points_df





from scipy.interpolate import interp1d
imu_df = df_action.copy()
lidar_df = points_df.copy()


imu_time = imu_df['Time']  # nanoseconds since epoch
lidar_time = lidar_df['Time']


interpolated = {}
for col in ['angular_velocity.x', 'angular_velocity.y', 'angular_velocity.z',
            'linear_acceleration.x', 'linear_acceleration.y', 'linear_acceleration.z']:
    f_interp = interp1d(imu_time, imu_df[col].values, kind='linear', bounds_error=False, fill_value='extrapolate')
    interpolated[col] = f_interp(lidar_time)
for col in interpolated:
    lidar_df[col] = interpolated[col]


pose_time = df_pose['Time']  # nanoseconds since epoch
lidar_time = lidar_df['Time']

pose_cols = [
    'pose.position.x', 'pose.position.y', 'pose.position.z',
    'pose.orientation.x', 'pose.orientation.y', 'pose.orientation.z', 'pose.orientation.w'
]

pose_interp = {}
for col in pose_cols:
    f_interp = interp1d(pose_time, df_pose[col].values, kind='linear', bounds_error=False, fill_value='extrapolate')
    pose_interp[col] = f_interp(lidar_time)

for col in pose_interp:
    lidar_df[col] = pose_interp[col]



lidar_df.head()





group_df = lidar_df.copy().sort_values("Time")
#group_df.drop(["offset_time", "timestamp", 'header.seq', 'header.stamp.secs', 'header.stamp.nsecs'], axis = 1)
#group_df['group_id'] = np.floor(np.arange(len(group_df)) / 500).astype(int)

grouped_df = group_df.groupby('frame_id').agg('first').reset_index(drop=True)
grouped_df.head(2)


import plotly.graph_objects as go

# Sort by timestamp to ensure time order
group_df = group_df.sort_values('Time')

# Create the figure
fig = go.Figure()

# Add scatter points
# fig.add_trace(go.Scatter3d(
#     x=group_df['x'],
#     y=group_df['y'],
#     z=group_df['z'],
#     mode='markers+lines',  # Connect points in time order
#     marker=dict(size=3, color=group_df['timestamp'].astype(int), colorscale='Viridis'),
#     line=dict(color='red', width=1),
#     name='LiDAR Path'
# ))
fig.add_trace(go.Scatter3d(
    x=group_df['x'],
    y=group_df['y'],
    z=group_df['z'],
    mode='markers+lines',
    marker=dict(
        size=3,
        color=group_df['Time'].astype('int64'),  # convert datetime to int64 (ns)
        colorscale='Viridis'
    ),
    line=dict(color='red', width=1),
    name='LiDAR Path'
))
fig.show()


# plot trajectory only
fig = go.Figure()

fig.add_trace(go.Scatter3d(
    x=grouped_df['x'],
    y=grouped_df['y'],
    z=grouped_df['z'],
    mode='lines+markers',
    marker=dict(size=3, color=grouped_df['Time'].astype('int64')/1e9, colorscale='Viridis'),
    line=dict(width=2, color='blue'),
    name='Drone trajectory'
))
fig.show()


# plot only a few LiDAR frames
sample_frames = group_df['frame_id'].unique()[:50]  # first 10 frames
for f in sample_frames:
    frame_points = group_df[group_df['frame_id'] == f]
    fig.add_trace(go.Scatter3d(
        x=frame_points['x'],
        y=frame_points['y'],
        z=frame_points['z'],
        mode='markers',
        marker=dict(size=2),
        name=f'Frame {f}'
    ))
fig.update_scenes(
    aspectmode='data'
)
fig.show()


# plot only one frame at a time
frame_id = 0
frame_points = group_df[group_df['frame_id'] == frame_id]
fig = go.Figure(data=[go.Scatter3d(
    x=frame_points['x'], y=frame_points['y'], z=frame_points['z'],
    mode='markers',
    marker=dict(size=2, color=frame_points['reflectivity'], colorscale='Viridis')
)])
fig.show()


# side view - X and Z axes
plt.figure(figsize=(6,6))
plt.scatter(points_df['x'], points_df['z'], s=1, c='purple')
plt.xlabel('X')
plt.ylabel('Z')
plt.title('Side View of LiDAR (XZ plane)')
plt.show()


# side view - Y and Z axes
plt.figure(figsize=(6,6))
plt.scatter(points_df['y'], points_df['z'], s=1, c='purple')
plt.xlabel('Y')
plt.ylabel('Z')
plt.title('Side View of LiDAR (YZ plane)')
plt.show()


# side view - X and Y axes
plt.figure(figsize=(6,6))
plt.scatter(points_df['x'], points_df['y'], s=1, c='purple')
plt.xlabel('X')
plt.ylabel('Y')
plt.title('Side View of LiDAR (XY plane)')
plt.show()





# checking for missing values
total = 0
for i in range(len(grouped_df.columns)):
    total += sum(grouped_df.iloc[:,i].isna())
total


lidar_df.columns



continuous = ['x', 'y', 'z', 'pose.position.x', 'pose.position.y',
       'pose.position.z', 'pose.orientation.x', 'pose.orientation.y',
       'pose.orientation.z', 'pose.orientation.w']
response = [
    'angular_velocity.x', 'angular_velocity.y', 'angular_velocity.z',
    'linear_acceleration.x', 'linear_acceleration.y', 'linear_acceleration.z'
]
discrete = ['reflectivity', 'tag', 'line', 'point_num', 'lidar_id', 'Time']

# scale data
scaler = StandardScaler()
grouped_df[continuous] = scaler.fit_transform(grouped_df[continuous])

# combine
X_final = grouped_df[discrete + continuous]

grouped_df = grouped_df.sample(frac=1, random_state=42).reset_index(drop=True)

X_train, X_test, y_train, y_test = train_test_split(X_final, grouped_df[response], test_size=0.2, random_state=42)

model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.4f}")



