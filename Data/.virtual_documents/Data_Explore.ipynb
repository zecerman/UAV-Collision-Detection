import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor





df = pd.read_csv('subset_mid360_livox_lidar_01.csv')
print(df.head(5))

df_action = pd.read_csv("mid360_livox_imu.csv")
df_action.drop("Unnamed: 0", axis = 1, inplace = True)
df_action = df_action.loc[:, (df_action != 0).any(axis=0)]
print(df_action.head(5))





def parse_points(raw_string, frame_id=None):
    raw_string = raw_string.strip("[]")
    entries = raw_string.split(", ")
    parsed = []
    for entry in entries:
        fields = entry.split(";")
        point = {}
        for field in fields:
            if ":" in field:
                key, value = field.split(":", 1)
                point[key.strip()] = value.strip()
        if frame_id is not None:
            point['frame_id'] = frame_id  # Track source frame
        parsed.append(point)
    return parsed

# Apply to all rows
all_points = []
for idx, row in df.iterrows():
    raw = row['points']
    frame_id = row.get('frame_index', idx)  # Use frame_index if available
    try:
        parsed = parse_points(raw, frame_id)
        for point in parsed:
            for col in df.columns:
                if col != 'points':
                    point[col] = row[col]
        all_points.extend(parsed)
    except Exception as e:
        print(f"Error parsing row {idx}: {e}")

# Convert to DataFrame
points_df = pd.DataFrame(all_points)
points_df = points_df.apply(pd.to_numeric, errors='ignore')

points_df.drop(["header.frame_id", "rsvd"], axis = 1)
points_df['Time'] = pd.to_datetime(points_df['Time'])
points_df['timestamp'] = points_df['Time'] + pd.to_timedelta(points_df['offset_time'], unit='ns')



df_action





from scipy.interpolate import interp1d
imu_df = df_action.copy()
lidar_df = points_df.copy()


imu_time = imu_df['Time']  # nanoseconds since epoch
lidar_time = lidar_df['timestamp']


interpolated = {}
for col in ['angular_velocity.x', 'angular_velocity.y', 'angular_velocity.z',
            'linear_acceleration.x', 'linear_acceleration.y', 'linear_acceleration.z']:
    f_interp = interp1d(imu_time, imu_df[col].values, kind='linear', bounds_error=False, fill_value='extrapolate')
    interpolated[col] = f_interp(lidar_time)
for col in interpolated:
    lidar_df[col] = interpolated[col]


lidar_df.columns





group_df = lidar_df.copy()
group_df.drop(["offset_time", "timestamp", 'header.seq', 'header.stamp.secs', 'header.stamp.nsecs'], axis = 1)
#group_df['group_id'] = np.floor(np.arange(len(group_df)) / 150).astype(int)

agg_dict = {
    'x': 'mean',
    'y': 'mean',
    'z': 'mean',
    'linear_acceleration.x': 'mean',
    'linear_acceleration.y': 'mean',
    'linear_acceleration.z': 'mean',
    'angular_velocity.x': 'mean',
    'angular_velocity.y': 'mean',
    'angular_velocity.z': 'mean',
    'timestamp': 'first',  
    'header.frame_id': 'first' , 
    'tag': 'max',
    'line': 'max',
    'reflectivity': 'mean',
}

grouped_df = group_df.groupby('frame_id').agg(agg_dict).reset_index(drop=True)
grouped_df


import plotly.graph_objects as go

# Sort by timestamp to ensure time order
group_df = group_df.sort_values('timestamp')

# Create the figure
fig = go.Figure()

# Add scatter points
# fig.add_trace(go.Scatter3d(
#     x=group_df['x'],
#     y=group_df['y'],
#     z=group_df['z'],
#     mode='markers+lines',  # Connect points in time order
#     marker=dict(size=3, color=group_df['timestamp'].astype(int), colorscale='Viridis'),
#     line=dict(color='red', width=1),
#     name='LiDAR Path'
# ))
fig.add_trace(go.Scatter3d(
    x=group_df['x'],
    y=group_df['y'],
    z=group_df['z'],
    mode='markers+lines',
    marker=dict(
        size=3,
        color=group_df['timestamp'].astype('int64'),  # convert datetime to int64 (ns)
        colorscale='Viridis'
    ),
    line=dict(color='red', width=1),
    name='LiDAR Path'
))
fig.show()


# plot trajectory only
fig = go.Figure()

fig.add_trace(go.Scatter3d(
    x=grouped_df['x'],
    y=grouped_df['y'],
    z=grouped_df['z'],
    mode='lines+markers',
    marker=dict(size=3, color=grouped_df['timestamp'].astype('int64')/1e9, colorscale='Viridis'),
    line=dict(width=2, color='blue'),
    name='Drone trajectory'
))
fig.show()


# plot only a few LiDAR frames
sample_frames = group_df['frame_id'].unique()[:10]  # first 10 frames
for f in sample_frames:
    frame_points = group_df[group_df['frame_id'] == f]
    fig.add_trace(go.Scatter3d(
        x=frame_points['x'],
        y=frame_points['y'],
        z=frame_points['z'],
        mode='markers',
        marker=dict(size=2),
        name=f'Frame {f}'
    ))
fig.show()


# plot only one frame at a time
frame_id = 0
frame_points = group_df[group_df['frame_id'] == frame_id]
fig = go.Figure(data=[go.Scatter3d(
    x=frame_points['x'], y=frame_points['y'], z=frame_points['z'],
    mode='markers',
    marker=dict(size=2, color=frame_points['reflectivity'], colorscale='Viridis')
)])
fig.show()


# side view
plt.figure(figsize=(6,6))
plt.scatter(points_df['x'], points_df['z'], s=1, c='purple')
plt.xlabel('X')
plt.ylabel('Z')
plt.title('Side View of LiDAR (XZ plane)')
plt.show()





def parse_points(raw_string, frame_id=None, timestamp=None, imu_data=None):
    raw_string = raw_string.strip("[]")
    entries = raw_string.split(", ")
    parsed = []

    for entry in entries:
        fields = entry.split(";")
        point = {}
        for field in fields:
            if ":" in field:
                key, value = field.split(":", 1)
                point[key.strip()] = value.strip()
        # Attach metadata
        if frame_id is not None:
            point['frame_id'] = frame_id
        if timestamp is not None:
            point['Time'] = timestamp
        if imu_data is not None:
            for k, v in imu_data.items():
                point[k] = v
        parsed.append(point)

    return parsed

all_points = []

for idx, row in lidar_df.iterrows():
    raw = row['points']
    frame_id = row.get('frame_index', idx)
    timestamp = row.get('Time', None)
    imu_data = {
        'point_num' : row.get('point_num'),
        'lidar_id' : row.get('lidar_id'),
        'angular_velocity.x': row.get('angular_velocity.x'),
        'angular_velocity.y': row.get('angular_velocity.y'),
        'angular_velocity.z': row.get('angular_velocity.z'),
        'linear_acceleration.x': row.get('linear_acceleration.x'),
        'linear_acceleration.y': row.get('linear_acceleration.y'),
        'linear_acceleration.z': row.get('linear_acceleration.z')
       
    }

    try:
        parsed = parse_points(raw, frame_id=frame_id, timestamp=timestamp, imu_data=imu_data)
        all_points.extend(parsed)
    except Exception as e:
        print(f"Error parsing row {idx}: {e}")

points_df = pd.DataFrame(all_points)
points_df = points_df.apply(pd.to_numeric, errors='ignore')
print(len(points_df))
points_df.head()








# checking for missing values
total = 0
for i in range(len(points_df.columns)):
    total += sum(points_df.iloc[:,i].isna())
total


continuous = ['offset_time', 'x', 'y', 'z']
response = [
    'angular_velocity.x', 'angular_velocity.y', 'angular_velocity.z',
    'linear_acceleration.x', 'linear_acceleration.y', 'linear_acceleration.z'
]
discrete = ['reflectivity', 'tag', 'line', 'point_num', 'lidar_id', 'frame_id']

# scale data
scaler = StandardScaler()
points_df[continuous] = scaler.fit_transform(points_df[continuous])

# combine
X_final = points_df[discrete + continuous]

points_df = points_df.sample(frac=1, random_state=42).reset_index(drop=True)

X_train, X_test, y_train, y_test = train_test_split(X_final, points_df[response], test_size=0.2, random_state=42)

model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.4f}")


print(points_df[response].nunique())
